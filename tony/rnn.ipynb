{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea9f615f-1564-401f-9a74-8ac98f9bbeab",
   "metadata": {
    "id": "ea9f615f-1564-401f-9a74-8ac98f9bbeab",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "from einops import rearrange,reduce,repeat\n",
    "from tqdm import trange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "OmXuKzlHSJhe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682873382169,
     "user": {
      "displayName": "Tapan Sahni",
      "userId": "00703842257004975160"
     },
     "user_tz": 420
    },
    "id": "OmXuKzlHSJhe",
    "outputId": "5461c0b0-aa0e-40ae-b5b9-c8b24f21bc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f44b0f51-0779-49dc-bcab-5c284039d6fd",
   "metadata": {
    "id": "f44b0f51-0779-49dc-bcab-5c284039d6fd"
   },
   "source": [
    "# MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68fac99f-9f5e-4fb5-ba6c-e22cc6f8f8be",
   "metadata": {
    "id": "68fac99f-9f5e-4fb5-ba6c-e22cc6f8f8be"
   },
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_dim, # input dimension\n",
    "                 out_dim, # output dimension\n",
    "                 hidden_dim, # hidden dimension\n",
    "                 num_layers # number of layers\n",
    "                ):\n",
    "        \n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        self.model = [nn.Linear(in_dim, 1024), nn.ReLU()]\n",
    "        self.model += [nn.Dropout(0.5)]\n",
    "        self.model += [nn.Linear(1024, 256), nn.ReLU()]\n",
    "        self.model += [nn.Linear(256, 128), nn.ReLU()]\n",
    "        #for i in range(num_layers-2):\n",
    "        #    self.model += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU()]\n",
    "        \n",
    "        \n",
    "        self.model += [nn.Linear(hidden_dim, out_dim)]\n",
    "        \n",
    "        self.model = nn.Sequential(*self.model)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        # Flatten the last two dimensions\n",
    "        inp = inp.reshape(inp.shape[0], -1)\n",
    "        \n",
    "        out = self.model(inp)\n",
    "        \n",
    "        #bz x outputlength x 2\n",
    "        return out.reshape(inp.shape[0], -1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5cc0cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        h_t, c_t = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, (h_t, c_t) = self.lstm(x, (h_t, c_t))\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, (h_t, c_t)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        h_0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c_0 =  torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)       \n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return h_0, c_0\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43901b7a-983c-49ca-b02a-e22d812f3cab",
   "metadata": {
    "id": "43901b7a-983c-49ca-b02a-e22d812f3cab"
   },
   "outputs": [],
   "source": [
    "# Autogressive vs. direct mapping\n",
    "# Batch Norm? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c020112-bb96-45d0-abf4-332956e8e544",
   "metadata": {
    "id": "1c020112-bb96-45d0-abf4-332956e8e544"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc5190e9-67a3-4e83-af0c-2f79f9cab867",
   "metadata": {
    "id": "cc5190e9-67a3-4e83-af0c-2f79f9cab867"
   },
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_path,\n",
    "                 sample_indices):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.sample_indices = sample_indices\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Load one scene\n",
    "        pkl_path = self.pkl_list[self.sample_indices[idx]]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            scene = pickle.load(f)\n",
    "            \n",
    "        # the index of agent to be predicted \n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        \n",
    "        # input: p_in & v_in; output: p_out\n",
    "        p_in_raw = scene['p_in']\n",
    "        p_out_raw = scene['p_out'][pred_id]\n",
    "        v_in_raw = scene['v_in']\n",
    "        v_out_raw = scene['v_out'][pred_id]\n",
    "        lane_scene = scene['lane']\n",
    "        \n",
    "        # Normalization\n",
    "        min_vecs = np.min(lane_scene, axis = 0)\n",
    "        max_vecs = np.max(lane_scene, axis = 0)\n",
    "        \n",
    "        # Normalize by vectors\n",
    "        p_in_normalized = (p_in_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        p_out_normalized = (p_out_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        v_in_norm = np.linalg.norm(v_in_raw, axis=1, keepdims=True)\n",
    "        v_in_norm = np.where(v_in_norm == 0.0, 1.0, v_in_norm)\n",
    "        v_in_normalized = v_in_raw / v_in_norm\n",
    "        # v_out_normalized = v_out_raw / np.linalg.norm(v_out_raw, axis=1, keepdims=True)\n",
    "        inp = np.concatenate((p_in_normalized,v_in_normalized),axis=1)\n",
    "        \n",
    "        # Convert to float torch tensor\n",
    "        return torch.from_numpy(inp).float(), torch.from_numpy(p_out_normalized).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14e48233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 data_path,\n",
    "                 sample_indices):\n",
    "        self.data_path = data_path\n",
    "        self.sample_indices = sample_indices\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # Load one scene\n",
    "        pkl_path = self.pkl_list[self.sample_indices[idx]]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            scene = pickle.load(f)\n",
    "        # the index of agent to be predicted \n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        mask = np.where(scene['car_mask'] == 1)[0]\n",
    "    \n",
    "        \n",
    "        # input: p_in & v_in; output: p_out\n",
    "        p_in_raw = scene['p_in']\n",
    "        p_out_raw = scene['p_out'][pred_id]\n",
    "        v_in_raw = scene['v_in']\n",
    "        \n",
    "        lane_scene = scene['lane']\n",
    "        \n",
    "        # Normalization\n",
    "        min_vecs = np.min(lane_scene, axis = 0)\n",
    "        max_vecs = np.max(lane_scene, axis = 0)\n",
    "        \n",
    "        # Normalize by vectors\n",
    "        p_in_norm = (p_in_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        \n",
    "        v_in_norm = np.linalg.norm(v_in_raw, axis=1, keepdims=True)\n",
    "        v_in_norm = np.where(v_in_norm == 0.0, 1.0, v_in_norm)\n",
    "        v_in_norm = v_in_raw / v_in_norm\n",
    "        # v_out_normalized = v_out_raw / np.linalg.norm(v_out_raw, axis=1, keepdims=True)\n",
    "        p_track = p_in_norm[mask].reshape(-1,19*2)\n",
    "        v_track = v_in_norm[mask].reshape(-1,19*2)\n",
    "        \n",
    "        p_agent = p_in_norm[pred_id].reshape(1,-1)\n",
    "        v_agent = v_in_norm[pred_id].reshape(1,-1)\n",
    "        new_mask = []\n",
    "        p_result = []\n",
    "        v_result = []\n",
    "        if (len(mask) > 10):\n",
    "            \n",
    "            dist = ((p_track - p_agent)**2).sum(axis=-1)\n",
    "            #print('dist is ',dist.shape)\n",
    "            new_mask = np.argpartition(dist,10)[:10]\n",
    "            \n",
    "            p_result = p_track[new_mask,:]\n",
    "            v_result = v_track[new_mask,:]\n",
    "        else:\n",
    "            p_result = np.zeros((10,38))\n",
    "            v_result = np.zeros((10,38))\n",
    "            k = p_track.shape[0]\n",
    "            #print('slice',k)\n",
    "            p_result[:k] = p_track\n",
    "            v_result[:k] = v_track\n",
    "        \n",
    "        #print('shape is',p_agent.shape,v_agent.shape,p_result.shape,v_result.shape)\n",
    "        inp = np.vstack((p_agent,v_agent,p_result,v_result))\n",
    "        #print('inp shape is',inp.shape)\n",
    "\n",
    "\n",
    "        p_out_normalized = (p_out_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        p_out_norm = rearrange(p_out_normalized, 'a b -> (a b)')\n",
    "        # Convert to float torch tensor\n",
    "        return torch.from_numpy(inp).float(), torch.from_numpy(p_out_norm).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16e5f5c2-86ff-4a6b-a585-117d0d08b8b2",
   "metadata": {
    "id": "16e5f5c2-86ff-4a6b-a585-117d0d08b8b2"
   },
   "outputs": [],
   "source": [
    "# Try different ways of normalization\n",
    "# Leverage other features. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c13ae604-526c-4fff-a672-f09cd103f7c2",
   "metadata": {
    "id": "c13ae604-526c-4fff-a672-f09cd103f7c2"
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "913d832f-4050-4c23-9d74-114595112f13",
   "metadata": {
    "id": "913d832f-4050-4c23-9d74-114595112f13"
   },
   "outputs": [],
   "source": [
    "# Grid/Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29e5c051-43a7-4bfd-9ab0-7105693661d3",
   "metadata": {
    "id": "29e5c051-43a7-4bfd-9ab0-7105693661d3"
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "in_dim = 19*2\n",
    "out_dim = 30*2\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "learning_rate = 0.01\n",
    "decay_rate = 0.95\n",
    "num_epoch = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb7aa146-1618-4fc2-aec1-2724a09c8bd0",
   "metadata": {
    "id": "fb7aa146-1618-4fc2-aec1-2724a09c8bd0"
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d589c9c9-c46b-4b70-a515-90dd68669431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1682203235553,
     "user": {
      "displayName": "Dev Gulati",
      "userId": "17053533454866203676"
     },
     "user_tz": 420
    },
    "id": "d589c9c9-c46b-4b70-a515-90dd68669431",
    "outputId": "34773f5c-9441-4dd7-903b-970cb0e59e99"
   },
   "outputs": [],
   "source": [
    "train_path = \"./train/train\"\n",
    "\n",
    "# total number of scenes\n",
    "indices = np.arange(0, 205942)\n",
    "\n",
    "# train-valid split\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:180000]\n",
    "valid_indices = indices[180000:]\n",
    "\n",
    "# define datasets\n",
    "train_set = ArgoverseDataset(train_path, train_indices)\n",
    "valid_set = ArgoverseDataset(train_path, valid_indices)\n",
    "\n",
    "train_set = RNNdataset(train_path, train_indices)\n",
    "valid_set = RNNdataset(train_path, valid_indices)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d9c45bc-bdf3-4b5a-82b0-c0752c16cd2b",
   "metadata": {
    "id": "6d9c45bc-bdf3-4b5a-82b0-c0752c16cd2b"
   },
   "source": [
    "# Model, Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c3cc020-8055-4005-ba6b-585a2e7a5fee",
   "metadata": {
    "id": "8c3cc020-8055-4005-ba6b-585a2e7a5fee"
   },
   "outputs": [],
   "source": [
    "# RNN, LSTM, 1dCNN, Transformer\n",
    "model = MLPNet(in_dim = in_dim, \n",
    "               out_dim = out_dim,\n",
    "               hidden_dim = hidden_dim, \n",
    "               num_layers = num_layers).to(device) # move model to gpu \n",
    "\n",
    "# Adaptive Moment Estimation computes adaptive learning rates for each parameter. \n",
    "# Compute the decaying averages of past and past squared gradients. \n",
    "# Instantiate the model with hyperparameters\n",
    "model = MyLSTM(input_size=in_dim, output_size=out_dim, hidden_dim=30, n_layers=2).to(device)   #maximum number of hidden size is 120\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=decay_rate)  # stepwise learning rate decay\n",
    "loss_fun = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c3392ee-eb57-4d8d-b6ea-49e6f38e3770",
   "metadata": {
    "id": "1c3392ee-eb57-4d8d-b6ea-49e6f38e3770"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa3e350d-9fca-4356-84da-7412d86667c9",
   "metadata": {
    "id": "fa3e350d-9fca-4356-84da-7412d86667c9"
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    model.train()\n",
    "    train_mse = []\n",
    "    for inp, tgt in train_loader:\n",
    "        inp = inp.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "       \n",
    "        \n",
    "        pred,_ = model(inp)\n",
    "        #print(pred.shape,tgt.shape)\n",
    "        pred = pred[:,-1, :].squeeze(1)\n",
    "        loss = loss_function(pred, tgt)\n",
    "        train_mse.append(loss.item()) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    model.eval()\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for inp, tgt in valid_loader:\n",
    "            inp = inp.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            \n",
    "            loss = 0\n",
    "            pred,_ = model(inp)\n",
    "            #print(tgt.shape,pred.shape)\n",
    "            pred = pred[:,-1, :].squeeze(1)\n",
    "            loss = loss_function(pred, tgt)\n",
    "            preds.append(pred.cpu().data.numpy())\n",
    "            trues.append(tgt.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item())\n",
    "            \n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse, preds, trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f529da48-7092-4096-b95d-a3782e0a7590",
   "metadata": {
    "id": "f529da48-7092-4096-b95d-a3782e0a7590"
   },
   "outputs": [],
   "source": [
    "# Learning Rate Decay\n",
    "# Dropout\n",
    "# L1/L2 Regulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5c15057-a83e-44b0-af97-cf28f3c98044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "error",
     "timestamp": 1682203248929,
     "user": {
      "displayName": "Dev Gulati",
      "userId": "17053533454866203676"
     },
     "user_tz": 420
    },
    "id": "f5c15057-a83e-44b0-af97-cf28f3c98044",
    "outputId": "c23108e3-db6e-4d40-8242-42cf968e5c13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:47<13:16:30, 47.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 1 | T: 0.80 | Train RMSE: 0.19336 | Valid RMSE: 0.07838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [01:27<11:55:28, 43.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 2 | T: 0.66 | Train RMSE: 0.06624 | Valid RMSE: 0.05358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [02:06<11:21:54, 41.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 3 | T: 0.64 | Train RMSE: 0.04851 | Valid RMSE: 0.04071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [02:48<11:26:49, 41.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 4 | T: 0.70 | Train RMSE: 0.03886 | Valid RMSE: 0.03646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [03:27<11:13:51, 40.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 5 | T: 0.66 | Train RMSE: 0.03594 | Valid RMSE: 0.03362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [04:06<11:04:24, 40.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | T: 0.65 | Train RMSE: 0.03444 | Valid RMSE: 0.03792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [04:45<10:57:07, 39.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | T: 0.65 | Train RMSE: 0.03418 | Valid RMSE: 0.03690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [05:20<10:32:13, 38.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | T: 0.59 | Train RMSE: 0.03329 | Valid RMSE: 0.03384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [06:00<10:40:39, 38.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | T: 0.67 | Train RMSE: 0.03304 | Valid RMSE: 0.03406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [06:37<10:32:06, 38.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 10 | T: 0.62 | Train RMSE: 0.03277 | Valid RMSE: 0.03182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [07:14<10:25:06, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | T: 0.62 | Train RMSE: 0.03265 | Valid RMSE: 0.03506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [07:54<10:31:49, 38.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | T: 0.66 | Train RMSE: 0.03225 | Valid RMSE: 0.03203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [08:31<10:26:15, 38.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 13 | T: 0.62 | Train RMSE: 0.03188 | Valid RMSE: 0.03162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [09:10<10:30:41, 38.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | T: 0.65 | Train RMSE: 0.03173 | Valid RMSE: 0.03234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [09:47<10:20:47, 37.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 15 | T: 0.61 | Train RMSE: 0.03164 | Valid RMSE: 0.03142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [10:22<10:08:02, 37.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 16 | T: 0.59 | Train RMSE: 0.03145 | Valid RMSE: 0.03115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/1000 [10:57<9:57:40, 36.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | T: 0.58 | Train RMSE: 0.03120 | Valid RMSE: 0.03210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [11:37<10:14:05, 37.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 18 | T: 0.67 | Train RMSE: 0.03120 | Valid RMSE: 0.03066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [12:14<10:09:03, 37.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 19 | T: 0.61 | Train RMSE: 0.03100 | Valid RMSE: 0.03043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [12:49<9:57:16, 36.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | T: 0.58 | Train RMSE: 0.03082 | Valid RMSE: 0.03088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [13:27<10:03:28, 36.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 21 | T: 0.63 | Train RMSE: 0.03055 | Valid RMSE: 0.03036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [14:05<10:10:36, 37.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | T: 0.64 | Train RMSE: 0.03050 | Valid RMSE: 0.03075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [14:43<10:10:36, 37.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | T: 0.63 | Train RMSE: 0.03039 | Valid RMSE: 0.03088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [15:23<10:23:01, 38.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 24 | T: 0.67 | Train RMSE: 0.03046 | Valid RMSE: 0.03006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 25/1000 [16:02<10:27:22, 38.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | T: 0.66 | Train RMSE: 0.03015 | Valid RMSE: 0.03077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [16:41<10:27:54, 38.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | T: 0.65 | Train RMSE: 0.03025 | Valid RMSE: 0.03270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [17:17<10:12:58, 37.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | T: 0.60 | Train RMSE: 0.03015 | Valid RMSE: 0.03086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [17:57<10:23:09, 38.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | T: 0.67 | Train RMSE: 0.02999 | Valid RMSE: 0.03012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [18:39<10:38:18, 39.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | T: 0.70 | Train RMSE: 0.02986 | Valid RMSE: 0.03025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1000 [19:14<10:17:17, 38.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | T: 0.59 | Train RMSE: 0.02976 | Valid RMSE: 0.03043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [19:53<10:20:21, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 31 | T: 0.65 | Train RMSE: 0.02969 | Valid RMSE: 0.02981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [20:28<10:03:46, 37.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 32 | T: 0.59 | Train RMSE: 0.02970 | Valid RMSE: 0.02976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1000 [21:11<10:28:32, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | T: 0.71 | Train RMSE: 0.02961 | Valid RMSE: 0.03021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1000 [21:47<10:16:10, 38.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 34 | T: 0.61 | Train RMSE: 0.02954 | Valid RMSE: 0.02966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35/1000 [22:25<10:14:19, 38.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | T: 0.63 | Train RMSE: 0.02941 | Valid RMSE: 0.02979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 36/1000 [23:02<10:08:03, 37.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 36 | T: 0.62 | Train RMSE: 0.02940 | Valid RMSE: 0.02952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [23:39<10:00:27, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 37 | T: 0.61 | Train RMSE: 0.02935 | Valid RMSE: 0.02951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 38/1000 [24:22<10:28:10, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 38 | T: 0.72 | Train RMSE: 0.02934 | Valid RMSE: 0.02932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1000 [25:03<10:35:52, 39.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | T: 0.68 | Train RMSE: 0.02924 | Valid RMSE: 0.02968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [25:41<10:28:44, 39.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | T: 0.64 | Train RMSE: 0.02921 | Valid RMSE: 0.02933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [26:16<10:06:59, 37.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | T: 0.58 | Train RMSE: 0.02914 | Valid RMSE: 0.02949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1000 [26:55<10:09:28, 38.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | T: 0.64 | Train RMSE: 0.02913 | Valid RMSE: 0.02934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 43/1000 [27:33<10:09:14, 38.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | T: 0.64 | Train RMSE: 0.02898 | Valid RMSE: 0.02953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1000 [28:08<9:54:41, 37.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best model\n",
      "Epoch 44 | T: 0.59 | Train RMSE: 0.02904 | Valid RMSE: 0.02920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [28:43<9:43:27, 36.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | T: 0.59 | Train RMSE: 0.02894 | Valid RMSE: 0.02935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [29:00<10:15:38, 38.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      8\u001b[0m \u001b[39m# model.train() # if you use dropout or batchnorm. \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_rmse\u001b[39m.\u001b[39mappend(train_epoch(train_loader, model, optimizer, loss_fun))\n\u001b[1;32m     11\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m val_rmse, val_preds, val_trues \u001b[39m=\u001b[39m eval_epoch(valid_loader, model, loss_fun)\n",
      "Cell \u001b[0;32mIn[82], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     13\u001b[0m     train_mse\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem()) \n\u001b[1;32m     14\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m train_mse \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean(train_mse)),\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_rmse = []\n",
    "valid_rmse = []\n",
    "min_rmse = 10e8\n",
    "\n",
    "for i in trange(num_epoch):\n",
    "    start = time.time()\n",
    "\n",
    "    # model.train() # if you use dropout or batchnorm. \n",
    "    train_rmse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "\n",
    "    # model.eval()\n",
    "    val_rmse, val_preds, val_trues = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_rmse.append(val_rmse)\n",
    "\n",
    "    # save the best model\n",
    "    if valid_rmse[-1] < min_rmse:\n",
    "        min_rmse = valid_rmse[-1] \n",
    "        best_model = model\n",
    "        print('Get best model')\n",
    "        # torch.save([best_model, i, get_lr(optimizer)], name + \".pth\")\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    # Early Stopping\n",
    "    if (len(train_rmse) > 100 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "            break       \n",
    "\n",
    "    # Learning Rate Decay        \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"Epoch {} | T: {:0.2f} | Train RMSE: {:0.5f} | Valid RMSE: {:0.5f}\".format(i + 1, (end-start) / 60, train_rmse[-1], valid_rmse[-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "540da579-31a5-462c-826b-e8e1c1a2ddd9",
   "metadata": {
    "id": "540da579-31a5-462c-826b-e8e1c1a2ddd9"
   },
   "source": [
    "# Evaluation and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66654867-c45e-4ad2-bdb4-ce1d546ea2d2",
   "metadata": {
    "id": "66654867-c45e-4ad2-bdb4-ce1d546ea2d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_path = \"./val_in/val_in/\"\n",
    "test_pkl_list = glob(os.path.join(test_path, '*'))\n",
    "test_pkl_list.sort()\n",
    "\n",
    "test_preds = []\n",
    "for idx in range(len(test_pkl_list)):\n",
    "    with open(test_pkl_list[idx], 'rb') as f:\n",
    "        test_sample = pickle.load(f)\n",
    "        pred_id = np.where(test_sample[\"track_id\"] == test_sample['agent_id'])[0][0]\n",
    "        mask = np.where(test_sample['car_mask'] == 1)[0]\n",
    "        # input: p_in & v_in; output: p_out\n",
    "        \n",
    "        p_in_raw = test_sample['p_in']\n",
    "        #p_out_raw = test_sample['p_out'][pred_id]\n",
    "        v_in_raw = test_sample['v_in']\n",
    "        lane_scene = test_sample['lane']\n",
    "        \n",
    "        # Normalization\n",
    "        min_vecs = np.min(lane_scene, axis = 0)\n",
    "        max_vecs = np.max(lane_scene, axis = 0)\n",
    "        \n",
    "        # Normalize by vectors\n",
    "        p_in_norm = (p_in_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        \n",
    "        v_in_norm = np.linalg.norm(v_in_raw, axis=1, keepdims=True)\n",
    "        v_in_norm = np.where(v_in_norm == 0.0, 1.0, v_in_norm)\n",
    "        v_in_norm = v_in_raw / v_in_norm\n",
    "        # v_out_normalized = v_out_raw / np.linalg.norm(v_out_raw, axis=1, keepdims=True)\n",
    "        p_track = p_in_norm[mask].reshape(-1,19*2)\n",
    "        v_track = v_in_norm[mask].reshape(-1,19*2)\n",
    "        \n",
    "        p_agent = p_in_norm[pred_id].reshape(1,-1)\n",
    "        v_agent = v_in_norm[pred_id].reshape(1,-1)\n",
    "        new_mask = []\n",
    "        p_result = []\n",
    "        v_result = []\n",
    "        if (len(mask) > 10):\n",
    "            \n",
    "            dist = ((p_track - p_agent)**2).sum(axis=-1)\n",
    "            #print('dist is ',dist.shape)\n",
    "            new_mask = np.argpartition(dist,10)[:10]\n",
    "            \n",
    "            p_result = p_track[new_mask,:]\n",
    "            v_result = v_track[new_mask,:]\n",
    "        else:\n",
    "            p_result = np.zeros((10,38))\n",
    "            v_result = np.zeros((10,38))\n",
    "            k = p_track.shape[0]\n",
    "            #print('slice',k)\n",
    "            p_result[:k] = p_track\n",
    "            v_result[:k] = v_track\n",
    "        \n",
    "        #print('shape is',p_agent.shape,v_agent.shape,p_result.shape,v_result.shape)\n",
    "        inp = np.vstack((p_agent,v_agent,p_result,v_result)).reshape(1,22,38)\n",
    "        inp = torch.from_numpy(inp).to(device,dtype=torch.float)\n",
    "        preds,_ = model(inp)\n",
    "        preds = preds.squeeze(0)\n",
    "        pred = preds[-1, :].cpu().data.numpy()\n",
    "        pred = rearrange(pred, \"(b c) -> b c\", c =2 )\n",
    "        # De-Normalization ! \n",
    "        pred = pred * (max_vecs[:2] - min_vecs[:2]) +  min_vecs[:2]\n",
    "        test_preds.append(pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f945f2f3-2b73-471f-91e5-87c63eb06a77",
   "metadata": {
    "id": "f945f2f3-2b73-471f-91e5-87c63eb06a77"
   },
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af9c27f8-a65b-48ce-861b-262c3f0422e6",
   "metadata": {
    "id": "af9c27f8-a65b-48ce-861b-262c3f0422e6"
   },
   "outputs": [],
   "source": [
    "# # Submission Files\n",
    "sample_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f01524a4-5473-4c1f-9991-46fd62162e20",
   "metadata": {
    "id": "f01524a4-5473-4c1f-9991-46fd62162e20"
   },
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "predictions = np.concatenate(test_preds).reshape(len(test_preds), -1).astype(int)\n",
    "sub_df = pd.DataFrame(np.c_[sample_sub[\"ID\"], predictions], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(1, 61)]]])\n",
    "sub_df.to_csv('test_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGiqLaD1PEDW",
   "metadata": {
    "id": "RGiqLaD1PEDW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
