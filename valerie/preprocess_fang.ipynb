{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205316, 22, 38)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npx = np.stack(X)\n",
    "npx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = np.stack(y)\n",
    "npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_X_clean.npy', 'wb') as f:\n",
    "    np.save(f, npx)\n",
    "\n",
    "with open('train_y_clean.npy', 'wb') as f:\n",
    "    np.save(f, npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_bad_data_points(positions, velocities, total_distance):\n",
    "    if total_distance < 10:\n",
    "        return positions, velocities\n",
    "    \n",
    "    positions_copy = np.copy(positions)\n",
    "    positions_copy[1:,:] = positions[:-1,:]\n",
    "    distances = np.linalg.norm(positions-positions_copy, axis=1)\n",
    "    bad_indices = np.where(distances[1:-1] == 0)[0]+1\n",
    "\n",
    "    if len(bad_indices) == 0:\n",
    "        return positions, velocities\n",
    "\n",
    "    positions_copy = np.copy(positions)\n",
    "    velocities_copy = np.copy(velocities)\n",
    "    for index in bad_indices:\n",
    "        positions_copy[index] = (positions[index - 1] + positions[index + 1]) / 2\n",
    "\n",
    "    bad_indices = np.where(distances[1:-1] == 0)[0]+1\n",
    "    for index in bad_indices:\n",
    "        velocities_copy[index] = (velocities[index - 1] + velocities[index + 1]) / 2\n",
    "\n",
    "    return positions_copy, velocities_copy\n",
    "\n",
    "def detect_outlier(folder, file_name, thresh, agent_only=True, verbose=True):\n",
    "    with open(os.path.join(folder, file_name + '.pkl'), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    num_cars = data['car_mask'].astype(int).sum()\n",
    "    if 'p_out' in data:\n",
    "        car_points = np.concatenate((data['p_in'], data['p_out']), axis=1)\n",
    "        velocities = np.concatenate((data['v_in'], data['v_out']), axis=1)\n",
    "    else:\n",
    "        car_points = data['p_in']\n",
    "        velocities = data['v_in']\n",
    "    car_points = car_points[:num_cars, ...]\n",
    "    \n",
    "    if agent_only:\n",
    "        agent_idx = np.where(data['track_id'] == data['agent_id'])[0][0]\n",
    "        car_points = car_points[agent_idx]\n",
    "    \n",
    "    if agent_only:\n",
    "        axis1=1\n",
    "        axis2=0\n",
    "        total_distance = np.linalg.norm(car_points[0]-car_points[-1])\n",
    "    else:\n",
    "        axis1=2\n",
    "        axis2=1\n",
    "        total_distance = np.linalg.norm(car_points[:,0]-car_points[:,-1], axis=axis2)\n",
    "\n",
    "    car_points_copy = np.copy(car_points)\n",
    "    if agent_only:\n",
    "        car_points_copy[1:,:] = car_points[:-1,:]\n",
    "    else:\n",
    "        car_points_copy[:,1:,:] = car_points[:,:-1,:]\n",
    "    distances = np.linalg.norm(car_points-car_points_copy, axis=axis1)\n",
    "    prev_idx = np.argmax(distances, axis=axis2)\n",
    "\n",
    "    if agent_only:\n",
    "        prev = distances[prev_idx-1]\n",
    "        if verbose:\n",
    "            print((prev))\n",
    "            print(np.max(distances, axis=axis2),  np.median(distances, axis=axis2))\n",
    "        # return np.max(distances, axis=axis2) > thresh * prev\n",
    "        return np.any(distances > thresh)\n",
    "    else:\n",
    "        prev_idx = np.array([[i, idx-1] for i,idx in enumerate(prev_idx)])\n",
    "        prev = distances[prev_idx[:, 0], prev_idx[:, 1]]\n",
    "        diff = distances[:,1:] - distances[:,:-1]\n",
    "        if verbose:\n",
    "            print(distances[1])\n",
    "        for i,d in enumerate(distances):\n",
    "            total_d = total_distance[i]\n",
    "            if total_d > 5 and np.any(d > thresh):   \n",
    "                return True\n",
    "            \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import torch.nn\n",
    "from einops import rearrange,reduce,repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = glob(os.path.join('train', '*'))\n",
    "len(pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for pkl_path in tqdm(pkl_list):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        scene = pickle.load(f)\n",
    "\n",
    "    # discard outliers\n",
    "    folder, file_name = os.path.split(pkl_path)\n",
    "    file_name, _ = os.path.splitext(file_name)\n",
    "    if detect_outlier(folder, file_name, thresh=10, agent_only=False, verbose=False):\n",
    "        continue\n",
    "\n",
    "    # the index of agent to be predicted \n",
    "    pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "    mask = np.where(scene['car_mask'] == 1)[0]\n",
    "    \n",
    "    # input: p_in & v_in; output: p_out\n",
    "    p_in_raw = scene['p_in']\n",
    "    p_out_raw = scene['p_out'][pred_id]\n",
    "    v_in_raw = scene['v_in']\n",
    "    \n",
    "    lane_scene = scene['lane']\n",
    "    \n",
    "    # Normalization\n",
    "    min_vecs = np.min(lane_scene, axis = 0)\n",
    "    max_vecs = np.max(lane_scene, axis = 0)\n",
    "\n",
    "    # Normalize by vectors\n",
    "    p_in_norm = (p_in_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "    \n",
    "    v_in_norm = np.linalg.norm(v_in_raw, axis=1, keepdims=True)\n",
    "    v_in_norm = np.where(v_in_norm == 0.0, 1.0, v_in_norm)\n",
    "    v_in_norm = v_in_raw / v_in_norm\n",
    "    # v_out_normalized = v_out_raw / np.linalg.norm(v_out_raw, axis=1, keepdims=True)\n",
    "    p_track = p_in_norm[mask].reshape(-1,19*2)\n",
    "    v_track = v_in_norm[mask].reshape(-1,19*2)\n",
    "    \n",
    "    p_agent = p_in_norm[pred_id].reshape(1,-1)\n",
    "    v_agent = v_in_norm[pred_id].reshape(1,-1)\n",
    "    new_mask = []\n",
    "    p_result = []\n",
    "    v_result = []\n",
    "    if (len(mask) > 10):\n",
    "        \n",
    "        dist = ((p_track - p_agent)**2).sum(axis=-1)\n",
    "        #print('dist is ',dist.shape)\n",
    "        new_mask = np.argpartition(dist,10)[:10]\n",
    "        \n",
    "        p_result = p_track[new_mask,:]\n",
    "        v_result = v_track[new_mask,:]\n",
    "    else:\n",
    "        p_result = np.zeros((10,38))\n",
    "        v_result = np.zeros((10,38))\n",
    "        k = p_track.shape[0]\n",
    "        #print('slice',k)\n",
    "        p_result[:k] = p_track\n",
    "        v_result[:k] = v_track\n",
    "    \n",
    "    #print('shape is',p_agent.shape,v_agent.shape,p_result.shape,v_result.shape)\n",
    "    inp = np.vstack((p_agent,v_agent,p_result,v_result))\n",
    "    #print('inp shape is',inp.shape)\n",
    "\n",
    "\n",
    "    p_out_normalized = (p_out_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "    p_out_norm = rearrange(p_out_normalized, 'a b -> (a b)')\n",
    "    # Convert to float torch tensor\n",
    "    X.append(torch.from_numpy(inp).float()), y.append(torch.from_numpy(p_out_norm).float())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
