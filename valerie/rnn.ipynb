{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_path,\n",
    "                 sample_indices):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.sample_indices = sample_indices\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Load one scene\n",
    "        pkl_path = self.pkl_list[self.sample_indices[idx]]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            scene = pickle.load(f)\n",
    "            \n",
    "        # the index of agent to be predicted \n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        \n",
    "        # input: p_in & v_in; output: p_out\n",
    "        p_in_raw = scene['p_in'][pred_id]\n",
    "        p_out_raw = scene['p_out'][pred_id]\n",
    "        v_in_raw = scene['v_in'][pred_id]\n",
    "        v_out_raw = scene['v_out'][pred_id]\n",
    "        lane_scene = scene['lane']\n",
    "        \n",
    "        # Normalization\n",
    "        min_vecs = np.min(lane_scene, axis = 0)\n",
    "        max_vecs = np.max(lane_scene, axis = 0)\n",
    "        \n",
    "        # Normalize by vectors\n",
    "        p_in_normalized = (p_in_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        p_out_normalized = (p_out_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        v_in_norm = np.linalg.norm(v_in_raw, axis=1, keepdims=True)\n",
    "        v_in_norm = np.where(v_in_norm == 0.0, 1.0, v_in_norm)\n",
    "        v_in_normalized = v_in_raw / v_in_norm\n",
    "        v_out_norm = np.linalg.norm(v_out_raw, axis=1, keepdims=True)\n",
    "        v_out_norm = np.where(v_out_norm == 0.0, 1.0, v_out_norm)\n",
    "        v_out_normalized = v_out_raw / v_out_norm\n",
    "        inp = np.concatenate((p_in_normalized,v_in_normalized),axis=1)\n",
    "        output = np.concatenate((p_out_normalized, v_out_normalized), axis=1)\n",
    "        full = np.vstack((inp, output))\n",
    "\n",
    "        stack = []\n",
    "        for i in range(output.shape[0]):\n",
    "            stack.append(full[i:i+inp.shape[0], :])\n",
    "        stack = np.stack(stack)\n",
    "        \n",
    "        # Convert to float torch tensor\n",
    "        return torch.from_numpy(stack).float(), torch.from_numpy(output).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PVDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 x_data_path,\n",
    "                 y_data_path,\n",
    "                 sample_indices):\n",
    "        super(PVDataset, self).__init__()\n",
    "        \n",
    "        self.X = np.load(x_data_path)\n",
    "        self.y = np.load(y_data_path)\n",
    "        self.sample_indices = sample_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.X[idx]\n",
    "        sample_y = self.y[idx]\n",
    "        return torch.from_numpy(sample_x).float(), torch.from_numpy(sample_y).float()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "in_dim = 4\n",
    "in_len = 19\n",
    "out_dim = 4\n",
    "out_len = 30\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "decay_rate = 0.95\n",
    "num_epoch = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./train\"\n",
    "\n",
    "# total number of scenes\n",
    "indices = np.arange(0, 205942)\n",
    "\n",
    "# train-valid split\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:180000]\n",
    "valid_indices = indices[180000:]\n",
    "\n",
    "# define datasets\n",
    "train_set = PVDataset('train_X.npy', 'train_y.npy', train_indices)\n",
    "valid_set = PVDataset('train_X.npy', 'train_y.npy', valid_indices)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size=in_dim, hidden_size=hidden_dim, num_layers=num_layers, output_size=out_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=decay_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, criterion):\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        # inputs = torch.flatten(inputs, end_dim=1)\n",
    "        inputs = inputs.to(device)\n",
    "        # targets = torch.flatten(targets, end_dim=1)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # outputs = torch.zeros(targets.shape)\n",
    "        # for i in range(outputs.size(1)-in_len):\n",
    "        #     input_tensor = inputs[:, i:i+in_len, :]\n",
    "        #     input_tensor = input_tensor.to(device)\n",
    "        #     output_tensor = model(input_tensor)\n",
    "        #     outputs[:, i, :] = output_tensor\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def eval_epoch(valid_loader, model, criterion):\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            # inputs = torch.flatten(inputs, end_dim=1)\n",
    "            inputs = inputs.to(device)\n",
    "            # targets = torch.flatten(targets, end_dim=1)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # outputs = torch.zeros(targets.shape)\n",
    "            # for i in range(outputs.size(1)-in_len):\n",
    "            #     input_tensor = inputs[:, i:i+in_len, :]\n",
    "            #     input_tensor = input_tensor.to(device)\n",
    "            #     output_tensor = model(input_tensor)\n",
    "            #     outputs[:, i, :] = output_tensor\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    return val_loss / len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:28<00:00,  3.97it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | T: 1.57 | Train RMSE: 21.01097 | Valid RMSE: 0.02720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.86it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | T: 1.62 | Train RMSE: 14.41015 | Valid RMSE: 0.02699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:34<00:00,  3.72it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | T: 1.68 | Train RMSE: 14.21281 | Valid RMSE: 0.02689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:32<00:00,  3.82it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | T: 1.64 | Train RMSE: 14.08254 | Valid RMSE: 0.02629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.83it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | T: 1.64 | Train RMSE: 13.93683 | Valid RMSE: 0.02587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.86it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | T: 1.62 | Train RMSE: 13.70345 | Valid RMSE: 0.02588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:28<00:00,  3.98it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | T: 1.57 | Train RMSE: 13.64278 | Valid RMSE: 0.02605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.86it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | T: 1.62 | Train RMSE: 13.52236 | Valid RMSE: 0.02549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.04it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | T: 1.55 | Train RMSE: 13.46840 | Valid RMSE: 0.02526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.90it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | T: 1.60 | Train RMSE: 13.41813 | Valid RMSE: 0.02556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.85it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | T: 1.63 | Train RMSE: 13.34704 | Valid RMSE: 0.02499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.86it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | T: 1.62 | Train RMSE: 13.29338 | Valid RMSE: 0.02515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:26<00:00,  4.08it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | T: 1.54 | Train RMSE: 13.24193 | Valid RMSE: 0.02471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.94it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | T: 1.59 | Train RMSE: 13.22012 | Valid RMSE: 0.02484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.89it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | T: 1.61 | Train RMSE: 13.16651 | Valid RMSE: 0.02470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.90it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | T: 1.61 | Train RMSE: 13.12752 | Valid RMSE: 0.02454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:28<00:00,  3.96it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | T: 1.58 | Train RMSE: 13.04689 | Valid RMSE: 0.02442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.87it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | T: 1.61 | Train RMSE: 12.99800 | Valid RMSE: 0.02437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:26<00:00,  4.05it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | T: 1.55 | Train RMSE: 12.92008 | Valid RMSE: 0.02406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:28<00:00,  3.99it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | T: 1.57 | Train RMSE: 12.86380 | Valid RMSE: 0.02400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.95it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | T: 1.58 | Train RMSE: 12.80187 | Valid RMSE: 0.02369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.00it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | T: 1.57 | Train RMSE: 12.71261 | Valid RMSE: 0.02370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.85it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | T: 1.63 | Train RMSE: 12.63393 | Valid RMSE: 0.02330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.84it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | T: 1.63 | Train RMSE: 12.51504 | Valid RMSE: 0.02308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.91it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | T: 1.60 | Train RMSE: 12.40054 | Valid RMSE: 0.02293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.00it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | T: 1.57 | Train RMSE: 12.24134 | Valid RMSE: 0.02243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.92it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | T: 1.60 | Train RMSE: 12.12802 | Valid RMSE: 0.02221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.88it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | T: 1.62 | Train RMSE: 11.98741 | Valid RMSE: 0.02181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.87it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | T: 1.62 | Train RMSE: 11.82493 | Valid RMSE: 0.02152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:28<00:00,  3.97it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | T: 1.57 | Train RMSE: 11.64320 | Valid RMSE: 0.02138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.90it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | T: 1.61 | Train RMSE: 11.48151 | Valid RMSE: 0.02085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:31<00:00,  3.86it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | T: 1.62 | Train RMSE: 11.31148 | Valid RMSE: 0.02057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.88it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | T: 1.61 | Train RMSE: 11.14895 | Valid RMSE: 0.02021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:28<00:00,  3.96it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | T: 1.58 | Train RMSE: 11.00047 | Valid RMSE: 0.01994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.95it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | T: 1.59 | Train RMSE: 10.86671 | Valid RMSE: 0.01968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:26<00:00,  4.07it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | T: 1.54 | Train RMSE: 10.71951 | Valid RMSE: 0.01931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.93it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | T: 1.59 | Train RMSE: 10.57742 | Valid RMSE: 0.01902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.93it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | T: 1.59 | Train RMSE: 10.44362 | Valid RMSE: 0.01874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:30<00:00,  3.87it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | T: 1.62 | Train RMSE: 10.32821 | Valid RMSE: 0.01844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:33<00:00,  3.78it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | T: 1.65 | Train RMSE: 10.20520 | Valid RMSE: 0.01834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.00it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | T: 1.56 | Train RMSE: 10.10072 | Valid RMSE: 0.01798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.03it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | T: 1.56 | Train RMSE: 9.95384 | Valid RMSE: 0.01772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:29<00:00,  3.94it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | T: 1.58 | Train RMSE: 9.84681 | Valid RMSE: 0.01756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.04it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | T: 1.55 | Train RMSE: 9.76805 | Valid RMSE: 0.01743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:27<00:00,  4.04it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | T: 1.55 | Train RMSE: 9.67842 | Valid RMSE: 0.01719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 103/352 [00:26<01:03,  3.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-fcfb1b2b76ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# if you use dropout or batchnorm.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain_rmse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-aa8c7d469109>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(train_loader, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\10954\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\10954\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_rmse = []\n",
    "valid_rmse = []\n",
    "min_rmse = 10e8\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    start = time.time()\n",
    "\n",
    "    model.train() # if you use dropout or batchnorm. \n",
    "    train_rmse.append(train_epoch(train_loader, model, optimizer, criterion))\n",
    "\n",
    "    model.eval()\n",
    "    valid_rmse.append(eval_epoch(valid_loader, model, criterion))\n",
    "\n",
    "    # save the best model\n",
    "    if valid_rmse[-1] < min_rmse:\n",
    "        min_rmse = valid_rmse[-1] \n",
    "        best_model = model\n",
    "        torch.save([best_model, epoch, get_lr(optimizer)], \"model.pth\")\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    # Early Stopping\n",
    "    if (len(train_rmse) > 100 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "            break       \n",
    "\n",
    "    # Learning Rate Decay        \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"Epoch {} | T: {:0.2f} | Train RMSE: {:0.5f} | Valid RMSE: {:0.5f}\".format(epoch + 1, (end-start) / 60, train_rmse[-1], valid_rmse[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(4, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, _, _ = torch.load('model.pth')\n",
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [05:35<00:00,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"./test\"\n",
    "test_pkl_list = glob(os.path.join(test_path, '*'))\n",
    "test_pkl_list.sort()\n",
    "\n",
    "test_preds = []\n",
    "best_model.eval()\n",
    "for test_pkl_path in tqdm(test_pkl_list):\n",
    "    with open(test_pkl_path, 'rb') as f:\n",
    "        scene = pickle.load(f)\n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        # input: p_in & v_in; output: p_out\n",
    "        p_in_raw = scene['p_in'][pred_id]\n",
    "        v_in_raw = scene['v_in'][pred_id]\n",
    "        lane_scene = scene['lane']\n",
    "        \n",
    "        # Normalization\n",
    "        min_vecs = np.min(lane_scene, axis = 0)\n",
    "        max_vecs = np.max(lane_scene, axis = 0)\n",
    "        \n",
    "        # Normalize by vectors\n",
    "        p_in_normalized = (p_in_raw - min_vecs)/(max_vecs - min_vecs)\n",
    "        v_in_norm = np.linalg.norm(v_in_raw, axis=1, keepdims=True)\n",
    "        v_in_norm = np.where(v_in_norm == 0.0, 1.0, v_in_norm)\n",
    "        v_in_normalized = v_in_raw / v_in_norm\n",
    "        inp = np.concatenate((p_in_normalized,v_in_normalized),axis=1)\n",
    "        inp = torch.from_numpy(inp).float().unsqueeze(0).to(device)\n",
    "\n",
    "        output = []\n",
    "        for i in range(out_len):\n",
    "            test_x = inp[:,-in_len:,:]\n",
    "            pred = best_model(test_x)\n",
    "            output.append(pred)\n",
    "            inp = torch.cat((inp, pred.unsqueeze(0)), dim=1)\n",
    "        output = torch.vstack(output)\n",
    "        output = output.detach().numpy()[:,:2]\n",
    "        \n",
    "        # De-Normalization ! \n",
    "        output = output * (max_vecs[:2] - min_vecs[:2]) +  min_vecs[:2]\n",
    "        test_preds.append(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Submission Files\n",
    "sample_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "predictions = np.concatenate(test_preds).reshape(len(test_preds), -1).astype(int)\n",
    "sub_df = pd.DataFrame(np.c_[sample_sub[\"ID\"], predictions], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(1, 61)]]])\n",
    "sub_df.to_csv('rnn_test_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID     float64\n",
       "v1     float64\n",
       "v2     float64\n",
       "v3     float64\n",
       "v4     float64\n",
       "        ...   \n",
       "v56    float64\n",
       "v57    float64\n",
       "v58    float64\n",
       "v59    float64\n",
       "v60    float64\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
